{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In the previous lesson, we have learnt how to import data and process them, so that they are ready to be used for the next step in the AI process - Modelling. \n",
    "\n",
    "There are many different types of machine learning techniques which can be used to run different [machine learning tasks](https://developers.google.com/machine-learning/problem-framing/cases) such as classification, regression, and clustering. In this session, we will create our own models to make predictions, cluster data, etc. The skills you will gain here will be used again to create your solution!  \n",
    "\n",
    "## Machine Learning\n",
    "Machine learning refers to the ability of the computer to learn patterns and relationships between data variables. They can do this through previous examples or learning from current datasets. Read this [article](https://hackernoon.com/the-simplest-explanation-of-machine-learning-youll-ever-read-bebc0700047c) to find out more about machine learning. Write down any information that you find interesting in your worksheet.\n",
    "\n",
    "As explored previously, there are 2 main types of machine learning algorithms we want to explore: Supervised learning and unsupervised learning. Do you still remember the [difference between the two](https://towardsdatascience.com/supervised-vs-unsupervised-learning-14f68e32ea8d)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries!\n",
    "Let us first import the pandas library to help us work with our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Supervised Learning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you used the video sharing site Youtube before? Do you realise that it will recommend videos that it thinks you will like to watch? Do you notice that the videos recommended to you will be different compared to the videos recommended to your friends? How do you think it can do that? \n",
    "\n",
    "The Youtube recommendation technology uses something known as supervised learning techique. Every time you 'like' a video, Youtube will record down the information of the video: Its name, genre, length, uploaders, etc. The more you watch and 'like' videos, the more information will be recorded into the system. \n",
    "\n",
    "This data set will be used to train a supervised learning model which will then predict which video you might like. This is done by analysing the videos you have watched and 'liked', and looking at the similarities between the video information. In this case, the videos that you liked previously will be the features or the data that the model will train. On the other hand, the videos that you most likely will want to watch (watched by other people who liked the same videos as you) will be the labels or the targets to the model/technique. The model/technique essentially tries and \"match\" the features to the labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning techniques requires training data that is labelled. For example, in the previous example, a video can either be liked, not rated, or disliked. These are the labels that are necessary in the training data when training the model. With more training data, a more accurate model can be made. \n",
    "\n",
    "Label has to be appropriate. For example, if you want to predict the exam scores of a student given the number of hours spent studying, then the data must contain the exam scores for each student. This will allow the machine learning algorithm to learn from the examples given. \n",
    "\n",
    "Another important term in supervised learning techniques is 'features'. Features refer to the data that can be used to predict the target or label. Based on the example of the exam scores, the exam scores are the target and the number of hours spent studying is a feature. Other features for that example can include the number of questions practiced, amount of sleep before the exam, etc. \n",
    "\n",
    "With the features and labels/targets, the algorithm will then be able to \"learn\" the relationship between the features and labels/targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the articles https://towardsdatascience.com/explaining-supervised-learning-to-a-kid-c2236f423e0f and https://www.geeksforgeeks.org/supervised-unsupervised-learning/, and watch this [video](https://www.youtube.com/watch?v=cfj6yaYE86U) and answer the questions listed below in your worksheet. Pay more attention to supervised learning. It is ok if you do not understand unsupervised learning at this point.\n",
    "\n",
    "- Explain supervised learning in your own words.\n",
    "- Explain and give examples of the terms: features, labels/targets, machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning techniques can be used to either classify data into different groups or to predict the relationships between variables. Techniques that classify data return categories or groups. For example, if we want to predict whether there will be rain tomorrow, we can use an algorithm that will return categories such as raining or sunny. On the other hand, techniques that are used for regression return numerical solutions. For example, if we want to predict the amount of rain tomorrow, we can use an alogrithm than will return numbers instead of categories.\n",
    "\n",
    "Read this [article](https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/) and watch this [video](https://www.youtube.com/watch?v=f7YB73F0zDo) to find out more information about difference between classification and regression. While reading the article and watching the video, try to think of some scenarios where you will use classification and also some scenarios where you will use regression. List these scenarios in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After understanding what is supervised learning, we will now explore the different supervised learning techniques!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the graph! These are the height and weight samples of male and female. Notice how they are grouped together. Males tend to be taller and heavier as compared to females, and you can see that there is a noticeable grouping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./resources/KNN1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at the green dot, the unknown input. Looking at the data, would you say that the unknown input belong to the male data or the female data? Why? How would you determine that?\n",
    "\n",
    "Well, you can see that they are closer to the male data, and thus it is more likely that the unknown data represents a male as well. This method of determining a group by its distance to other, already known data points, is called the K-nearest neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbours (KNN) can be used in classification or regression problems. However, it is mainly used for classification problems. As the name suggests, this algorithm relies on the surrounding points or neighbours to determine its class or group. For example, if you are trying to classify an unknown point as either class A or class B using KNN and the majority of the points nearest to the unknown point are in class A, which class do you think the unknown point will be in?\n",
    "\n",
    "If you guessed class A, your answer is right. This is because KNN utilises the properties of the majority of the nearest points to decide how to classify unknown points. This is similar to the famous phrase \"birds of the same feather, flock together\". Likewise, you will expect points that are similar to be close to each other.\n",
    "\n",
    "Watch this [video](https://www.youtube.com/watch?v=MDniRwXizWo) to find out more about KNN. What are the main advantages and disadvantages of KNN? You will be using KNN in subsequent exercises. This is because it is an easy to use and flexible algorithm which can be used for many problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After understanding how KNN works, lets try to apply it to a hypothetical scenario. In this scenario, you want to predict if a device is a laptop or a computer using features such as price and amount of memory. As such, you plotted a scatter plot for all the data points that you have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./resources/KNN.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The x-axis shows the amount of memory (GB) whereas the y-axis shows the price (USD). The blue circles are data points for desktop whereas the orange circles are data points for laptops. The star represents the unknown point.\n",
    "\n",
    "Based on your understanding of KNN, will the unknown point be a desktop or laptop if we were to apply KNN with 3 nearest neighbours? Will your answer change if you were to use 4 nearest neighbours or 5 nearest neighbours? How about if you were to use 9 nearest neighbours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you realise that the unknown point will change its classification if you were to use 9 nearest neighbours? From the graph, it is quite obvious that the unknown point is not a desktop. However, due to KNN using the majority, it is possible for KNN to wrongly classify an unknown point if the wrong number of nearest neighbours were used. Thus, it is always important to identify the best number of nearest neighbours. We will see how this is done in the next few workshops when we learn how to tune the models! For now, it is sufficient to just understand why the number of neighbours is an important parameter in K nearest neighbours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying flowers using KNN and the Iris Flower dataset\n",
    "\n",
    "Let us now apply the KNN technique to the Iris Flower dataset. First, load the previously used Iris Flower dataset as a pandas dataframe. Download the file from this [link](http://archive.ics.uci.edu/ml/machine-learning-databases/iris/) if you did not download the dataset previously. The file to download is the iris.data file. You can refer to the picture (source: https://www.researchgate.net/figure/Trollius-ranunculoide-flower-with-measured-traits_fig6_272514310) below for more information. \n",
    "\n",
    "From the photo below, could you explain what is meant by sepal and petal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./resources/PetalSepal1.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's start by downloading and exploring the dataset!\n",
    "1. Download dataset from website provided\n",
    "2. Open csv file\n",
    "3. print first five rows to check dataset\n",
    "4. add column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/iris.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5.1</th>\n",
       "      <th>3.5</th>\n",
       "      <th>1.4</th>\n",
       "      <th>0.2</th>\n",
       "      <th>Iris-setosa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   5.1  3.5  1.4  0.2  Iris-setosa\n",
       "0  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "1  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "2  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "3  5.0  3.6  1.4  0.2  Iris-setosa\n",
       "4  5.4  3.9  1.7  0.4  Iris-setosa"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width        class\n",
       "0           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "1           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "2           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "3           5.0          3.6           1.4          0.2  Iris-setosa\n",
       "4           5.4          3.9           1.7          0.4  Iris-setosa"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"]\n",
    "df.columns = names\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up data for the KNN algorithm\n",
    "\n",
    "Let us try to use KNN to classify the dataset with the type of flower or class being the target variable. To help us do so, we need to convert the categorical classes into numbers so that it can be understood easier by the computer. We can do so through the usage of label encoding. \n",
    "\n",
    "### Label Encoding\n",
    "Label encoding refers to the assignment of a number for each category. For example, if you have to predict the weather and there are two classes, rainy or sunny, we can label rainy as 0 and sunny as 1 (see table below). In this way, we can convert the categories to numbers.\n",
    "\n",
    "How would you apply label encoding to the iris dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./resources/Label2.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert the class/flower type in the Iris Flower dataset into numbers. What are the different classes within the dataset? How many classes are there in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, label encode the different classes. 'Iris-setosa' can be 1, 'Iris-versicolor' can be 2 and 'Iris-virginica' can be 3. The code below will encode for one of the classes. Edit the code to encode for all the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-versicolor    50\n",
      "Iris-virginica     50\n",
      "Iris-setosa        49\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print number of data points in each class\n",
    "print(df['class'].value_counts())\n",
    "\n",
    "# Dictionary to input the different numbers for different classes\n",
    "label_encode = {\"class\": {\"Iris-setosa\":1}}\n",
    "\n",
    "# Use .replace to change the different classes into numbers\n",
    "df.replace(label_encode,inplace=True)\n",
    "\n",
    "# Print number of data points in each class to check if the classes have changed to numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Bonus: There is also another method to convert categories to numbers. The method is known as one-hot encoding. One-hot encoding changes the categories into binary (0 or 1) categories. For example, if you have raining or sunny days as categories, one hot encoding will add 2 more columns, rainy and sunny, to the dataframe. If the data point shows rainy, it will be converted to a value of 1 under the raining column and a value of 0 under the sunny column (see table below). Read this [article](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/) to find out more about one-hot encoding. Now, read this [article](http://queirozf.com/entries/one-hot-encoding-a-feature-on-a-pandas-dataframe-an-example) to learn how to do one-hot encoding for pandas. Import the Iris Flower dataset again as df2 and conduct the one-hot encoding for it.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./resources/Label1.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_1</th>\n",
       "      <th>class_Iris-versicolor</th>\n",
       "      <th>class_Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class_1  class_Iris-versicolor  class_Iris-virginica\n",
       "0          1                      0                     0\n",
       "1          1                      0                     0\n",
       "2          1                      0                     0\n",
       "3          1                      0                     0\n",
       "4          1                      0                     0\n",
       "..       ...                    ...                   ...\n",
       "144        0                      0                     1\n",
       "145        0                      0                     1\n",
       "146        0                      0                     1\n",
       "147        0                      0                     1\n",
       "148        0                      0                     1\n",
       "\n",
       "[149 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df['class'], prefix='class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You've learn how to conduct label encoding and one-hot encoding. We can now try out the KNN algorithm. We first have to import the KNN algorithm from scikit learn. [Scikit learn](https://scikit-learn.org/stable/) is an open source python library which contains numerous popular machine learning algorithms. What does scikit learn contain? What can it do? See the listed [examples](https://scikit-learn.org/stable/auto_examples/index.html) for inspiration! Are you brimming with excitement now?\n",
    "\n",
    "\n",
    "Now, try the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read this [link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) to find out how to use the KNeighborsClassifier from sklearn. Do you remember from earlier in this notebook that the number of neighbours is required for KNN? From the link, what is the default number of neighbors used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width\n",
      "0           4.9          3.0\n",
      "1           4.7          3.2\n",
      "2           4.6          3.1\n",
      "3           5.0          3.6\n",
      "4           5.4          3.9\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: class, dtype: object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'unknown'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Prameya\\Documents\\CBSE-Intel-AI-For-Youth-Data-Science-Bootcamp\\Notebooks\\5. Machine Learning\\[Jupyter - Youth] Module 17.ipynb Cell 41'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Prameya/Documents/CBSE-Intel-AI-For-Youth-Data-Science-Bootcamp/Notebooks/5.%20Machine%20Learning/%5BJupyter%20-%20Youth%5D%20Module%2017.ipynb#ch0000038?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(y\u001b[39m.\u001b[39mhead())\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Prameya/Documents/CBSE-Intel-AI-For-Youth-Data-Science-Bootcamp/Notebooks/5.%20Machine%20Learning/%5BJupyter%20-%20Youth%5D%20Module%2017.ipynb#ch0000038?line=8'>9</a>\u001b[0m \u001b[39m# Train KNN using the x and y values. This is done through the .fit method.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Prameya/Documents/CBSE-Intel-AI-For-Youth-Data-Science-Bootcamp/Notebooks/5.%20Machine%20Learning/%5BJupyter%20-%20Youth%5D%20Module%2017.ipynb#ch0000038?line=9'>10</a>\u001b[0m KNN \u001b[39m=\u001b[39m KNN\u001b[39m.\u001b[39;49mfit(x,y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Prameya/Documents/CBSE-Intel-AI-For-Youth-Data-Science-Bootcamp/Notebooks/5.%20Machine%20Learning/%5BJupyter%20-%20Youth%5D%20Module%2017.ipynb#ch0000038?line=10'>11</a>\u001b[0m \u001b[39m# Let us use the trained KNN to predict the type of flower if its sepal length = 5 and sepal_width = 3 We can use the .predict method to do so.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Prameya/Documents/CBSE-Intel-AI-For-Youth-Data-Science-Bootcamp/Notebooks/5.%20Machine%20Learning/%5BJupyter%20-%20Youth%5D%20Module%2017.ipynb#ch0000038?line=11'>12</a>\u001b[0m test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n",
      "File \u001b[1;32mc:\\Users\\Prameya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198\u001b[0m, in \u001b[0;36mKNeighborsClassifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_classification.py?line=178'>179</a>\u001b[0m \u001b[39m\"\"\"Fit the k-nearest neighbors classifier from the training dataset.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_classification.py?line=179'>180</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_classification.py?line=180'>181</a>\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_classification.py?line=193'>194</a>\u001b[0m \u001b[39m    The fitted k-nearest neighbors classifier.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_classification.py?line=194'>195</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_classification.py?line=195'>196</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m=\u001b[39m _check_weights(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_classification.py?line=197'>198</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y)\n",
      "File \u001b[1;32mc:\\Users\\Prameya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_base.py:420\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_base.py?line=416'>417</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_base.py?line=417'>418</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs_2d_ \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_base.py?line=419'>420</a>\u001b[0m check_classification_targets(y)\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_base.py?line=420'>421</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m []\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_base.py?line=421'>422</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(y\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Prameya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\multiclass.py:197\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/multiclass.py?line=188'>189</a>\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y)\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/multiclass.py?line=189'>190</a>\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/multiclass.py?line=190'>191</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/multiclass.py?line=191'>192</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/multiclass.py?line=194'>195</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/multiclass.py?line=195'>196</a>\u001b[0m ]:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/multiclass.py?line=196'>197</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'unknown'"
     ]
    }
   ],
   "source": [
    "# Initialise the KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier()\n",
    "# Extract out the x values and y values. x will be sepal_length and y will be classes\n",
    "x = df[['sepal_length','sepal_width']]\n",
    "y = df['class']\n",
    "# Print .head() of x and y to make sure the data is correct\n",
    "print(x.head())\n",
    "print(y.head())\n",
    "# Train KNN using the x and y values. This is done through the .fit method.\n",
    "KNN = KNN.fit(x,y)\n",
    "# Let us use the trained KNN to predict the type of flower if its sepal length = 5 and sepal_width = 3 We can use the .predict method to do so.\n",
    "test = pd.DataFrame()\n",
    "test['sepal_length'] = [5,8]\n",
    "test['sepal_width'] = [3,3.5]\n",
    "print(test)\n",
    "predict_flower = KNN.predict(test)\n",
    "# Print predict_flower\n",
    "print(predict_flower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use the default number of neighbors to try and classify the Iris Flower dataset. \n",
    "\n",
    "We will only use 2 features (sepal_length and sepal_width) initially. In the code below, these are included in the 'x' dataframe. The 'class' of the flower i.e. the name of the flower species will be the 'label', included in the 'y' dataframe. \n",
    "\n",
    "Try the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width\n",
      "0           4.9          3.0\n",
      "1           4.7          3.2\n",
      "2           4.6          3.1\n",
      "3           5.0          3.6\n",
      "4           5.4          3.9\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: class, dtype: object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'unknown'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Prameya\\Documents\\CBSE-Intel-AI-For-Youth-Data-Science-Bootcamp\\Notebooks\\5. Machine Learning\\[Jupyter - Youth] Module 17.ipynb Cell 43'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Prameya/Documents/CBSE-Intel-AI-For-Youth-Data-Science-Bootcamp/Notebooks/5.%20Machine%20Learning/%5BJupyter%20-%20Youth%5D%20Module%2017.ipynb#ch0000040?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(y\u001b[39m.\u001b[39mhead())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Prameya/Documents/CBSE-Intel-AI-For-Youth-Data-Science-Bootcamp/Notebooks/5.%20Machine%20Learning/%5BJupyter%20-%20Youth%5D%20Module%2017.ipynb#ch0000040?line=11'>12</a>\u001b[0m \u001b[39m# Train KNN using the x and y values. This is done through the .fit method.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Prameya/Documents/CBSE-Intel-AI-For-Youth-Data-Science-Bootcamp/Notebooks/5.%20Machine%20Learning/%5BJupyter%20-%20Youth%5D%20Module%2017.ipynb#ch0000040?line=12'>13</a>\u001b[0m KNN \u001b[39m=\u001b[39m KNN\u001b[39m.\u001b[39;49mfit(x,y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Prameya/Documents/CBSE-Intel-AI-For-Youth-Data-Science-Bootcamp/Notebooks/5.%20Machine%20Learning/%5BJupyter%20-%20Youth%5D%20Module%2017.ipynb#ch0000040?line=14'>15</a>\u001b[0m \u001b[39m# Let us use the trained KNN to predict the type of flower if its sepal length = 5 and sepal_width = 3 We can use the .predict method to do so.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Prameya/Documents/CBSE-Intel-AI-For-Youth-Data-Science-Bootcamp/Notebooks/5.%20Machine%20Learning/%5BJupyter%20-%20Youth%5D%20Module%2017.ipynb#ch0000040?line=15'>16</a>\u001b[0m test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n",
      "File \u001b[1;32mc:\\Users\\Prameya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198\u001b[0m, in \u001b[0;36mKNeighborsClassifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_classification.py?line=178'>179</a>\u001b[0m \u001b[39m\"\"\"Fit the k-nearest neighbors classifier from the training dataset.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_classification.py?line=179'>180</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_classification.py?line=180'>181</a>\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_classification.py?line=193'>194</a>\u001b[0m \u001b[39m    The fitted k-nearest neighbors classifier.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_classification.py?line=194'>195</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_classification.py?line=195'>196</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m=\u001b[39m _check_weights(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_classification.py?line=197'>198</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y)\n",
      "File \u001b[1;32mc:\\Users\\Prameya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_base.py:420\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_base.py?line=416'>417</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_base.py?line=417'>418</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs_2d_ \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_base.py?line=419'>420</a>\u001b[0m check_classification_targets(y)\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_base.py?line=420'>421</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m []\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/neighbors/_base.py?line=421'>422</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(y\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Prameya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\multiclass.py:197\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/multiclass.py?line=188'>189</a>\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y)\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/multiclass.py?line=189'>190</a>\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/multiclass.py?line=190'>191</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/multiclass.py?line=191'>192</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/multiclass.py?line=194'>195</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/multiclass.py?line=195'>196</a>\u001b[0m ]:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/multiclass.py?line=196'>197</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'unknown'"
     ]
    }
   ],
   "source": [
    "# Initialise the KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "# Extract out the x values and y values. x will be sepal_length and y will be classes\n",
    "x = df[['sepal_length','sepal_width']]\n",
    "y = df['class']\n",
    "\n",
    "# Print .head() of x and y to make sure the data is correct\n",
    "print(x.head())\n",
    "print(y.head())\n",
    "\n",
    "# Train KNN using the x and y values. This is done through the .fit method.\n",
    "KNN = KNN.fit(x,y)\n",
    "\n",
    "# Let us use the trained KNN to predict the type of flower if its sepal length = 5 and sepal_width = 3 We can use the .predict method to do so.\n",
    "test = pd.DataFrame()\n",
    "test['sepal_length'] = [5,8]\n",
    "test['sepal_width'] = [3,3.5]\n",
    "predict_flower = KNN.predict(test)\n",
    "\n",
    "# Print predict_flower\n",
    "print(predict_flower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output above, do you know which flower type was predicted for a data point with sepal length = 5 and sepal width = 3? Remember our encoding earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! What if the sepal length = 3 and sepal width = 5? Edit the code above to find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have trained your first supervised learning model. However, we only used 2 variables. Train another KNN model named KNN2 with all the other variables ('sepal_length','sepal_width','petal_length','petal_width') instead of just sepal length and sepal width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your new model, can you predict the flower type with sepal_length = 5.8, sepal_width = 2.3, petal_length = 5.0 and petal_width = 1.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You have used the k-nearest neighbour algorithm to train a classification model that can classify the types of flower given the characteristics of the flowers such as the sepal length, sepal width , petal length , and the petal width. \n",
    "\n",
    "How would this kind of models be useful? Write down your answer below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How else do you think the k-nearest neighbour algorithm can be used? Write down your answer below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many models that can be used for classification. Next, we will explore the decision tree to help us with classification as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another supervised machine learning technique is the decision tree. Watch this [video](https://www.youtube.com/watch?v=eKD5gxPPeY00) to find out more about decision trees. After watching, draw an example of a decision tree in your worksheet. You can refer to the example shown below.\n",
    "\n",
    "We make numerous decisions every day. How do you make certain decisions? What kind of decision tree will you draw? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./resources/dt1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another supervised machine learning technique is the decision tree. Watch this [video](https://www.youtube.com/watch?v=eKD5gxPPeY00) to find out more about decision trees. After watching, draw an example of a decision tree in your worksheet. You can refer to the example shown below.\n",
    "\n",
    "We make numerous decisions every day. How do you make certain decisions? What kind of decision tree will you draw? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to import the decision tree from scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use the same df dataframe from earlier in this notebook. The df dataframe contains the Iris Flower dataset and the outputs have been label encoded. We will first use the sepal length and sepal width as x values and the class as the targets/outputs or y values. Try the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width\n",
      "0           4.9          3.0\n",
      "1           4.7          3.2\n",
      "2           4.6          3.1\n",
      "3           5.0          3.6\n",
      "4           5.4          3.9\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: class, dtype: object\n",
      "     sepal_length  sepal_width\n",
      "0             4.9          3.0\n",
      "1             4.7          3.2\n",
      "2             4.6          3.1\n",
      "3             5.0          3.6\n",
      "4             5.4          3.9\n",
      "..            ...          ...\n",
      "144           6.7          3.0\n",
      "145           6.3          2.5\n",
      "146           6.5          3.0\n",
      "147           6.2          3.4\n",
      "148           5.9          3.0\n",
      "\n",
      "[149 rows x 2 columns] 0                   1\n",
      "1                   1\n",
      "2                   1\n",
      "3                   1\n",
      "4                   1\n",
      "            ...      \n",
      "144    Iris-virginica\n",
      "145    Iris-virginica\n",
      "146    Iris-virginica\n",
      "147    Iris-virginica\n",
      "148    Iris-virginica\n",
      "Name: class, Length: 149, dtype: object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'unknown'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Prameya\\Documents\\CBSE-Intel-AI-For-Youth-Data-Science-Bootcamp\\Notebooks\\5. Machine Learning\\[Jupyter - Youth] Module 17.ipynb Cell 66'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Prameya/Documents/CBSE-Intel-AI-For-Youth-Data-Science-Bootcamp/Notebooks/5.%20Machine%20Learning/%5BJupyter%20-%20Youth%5D%20Module%2017.ipynb#ch0000063?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(x, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Prameya/Documents/CBSE-Intel-AI-For-Youth-Data-Science-Bootcamp/Notebooks/5.%20Machine%20Learning/%5BJupyter%20-%20Youth%5D%20Module%2017.ipynb#ch0000063?line=12'>13</a>\u001b[0m \u001b[39m# Train decision tree using the x and y values. This is done through the .fit method.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Prameya/Documents/CBSE-Intel-AI-For-Youth-Data-Science-Bootcamp/Notebooks/5.%20Machine%20Learning/%5BJupyter%20-%20Youth%5D%20Module%2017.ipynb#ch0000063?line=13'>14</a>\u001b[0m dt \u001b[39m=\u001b[39m dt\u001b[39m.\u001b[39;49mfit(x, y)\n",
      "File \u001b[1;32mc:\\Users\\Prameya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=898'>899</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=899'>900</a>\u001b[0m     \u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, X_idx_sorted\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=900'>901</a>\u001b[0m ):\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=901'>902</a>\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=902'>903</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=903'>904</a>\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=933'>934</a>\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=934'>935</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=936'>937</a>\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=937'>938</a>\u001b[0m         X,\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=938'>939</a>\u001b[0m         y,\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=939'>940</a>\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=940'>941</a>\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=941'>942</a>\u001b[0m         X_idx_sorted\u001b[39m=\u001b[39;49mX_idx_sorted,\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=942'>943</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=943'>944</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Prameya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:203\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=199'>200</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=201'>202</a>\u001b[0m \u001b[39mif\u001b[39;00m is_classification:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=202'>203</a>\u001b[0m     check_classification_targets(y)\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=203'>204</a>\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(y)\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=205'>206</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Prameya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\multiclass.py:197\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/multiclass.py?line=188'>189</a>\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y)\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/multiclass.py?line=189'>190</a>\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/multiclass.py?line=190'>191</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/multiclass.py?line=191'>192</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/multiclass.py?line=194'>195</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/multiclass.py?line=195'>196</a>\u001b[0m ]:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Prameya/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/multiclass.py?line=196'>197</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'unknown'"
     ]
    }
   ],
   "source": [
    "# Initialise the Decision Tree\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Extract out the x values and y values. x will be sepal_length and y will be classes\n",
    "x = df[['sepal_length','sepal_width']]\n",
    "y = df['class']\n",
    "\n",
    "# Print .head() of x and y to make sure the data is correct\n",
    "print(x.head())\n",
    "print(y.head())\n",
    "print(x, y)\n",
    "\n",
    "# Train decision tree using the x and y values. This is done through the .fit method.\n",
    "dt = dt.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the initialisation code. Why do we use the DecisionTreeClassifier instead of the DecisionTreeRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, can you make a prediction using the trained tree? Can you predict the type of flower if its sepal length = 5 and sepal_width = 3? You can use the .predict method to do so. Edit the code below to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe called test2 with sepal_length and sepal_width as its columns. Sepal_length has been done for you in the code below.\n",
    "test2 = pd.DataFrame()\n",
    "test2['sepal_length'] = [5]\n",
    "\n",
    "# Use the .predict method to predict the new flower. You can call the predicted flower as predict_flower.\n",
    "predict_flower = KNN.predict(test)\n",
    "\n",
    "# Print predict_flower\n",
    "print(predict_flower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the predicted flower type and does it match with that predicted by K nearest neighbours earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, train a new decision tree, dt2, based on sepal length, sepal width, petal length and petal width. Predict the flower type with sepal_length = 5.8, sepal_width = 2.3, petal_length = 5.0 and petal_width = 1.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the flower type predicted by the new tree? Is it the same as that predicted by K-Nearest Neighbours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result above, we can see that while most machine learning techniques may be used to solve the same problem, the outcome/predictions may differ across models! As such, there is a need to choose which models to use based on the accuracy of the models. You will learn how to evaluate the quality of the models in the later workshops."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc72a3af264b0045735d19a958e44b2f4da1ab82dc967f6485e5d3ade304af55"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
